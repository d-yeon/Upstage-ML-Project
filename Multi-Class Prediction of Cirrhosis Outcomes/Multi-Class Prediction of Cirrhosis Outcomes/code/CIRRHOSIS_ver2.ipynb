{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1479\n",
      "           1       0.56      0.17      0.26        82\n",
      "           2       0.76      0.73      0.74       811\n",
      "\n",
      "    accuracy                           0.81      2372\n",
      "   macro avg       0.72      0.60      0.62      2372\n",
      "weighted avg       0.80      0.81      0.80      2372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "# pd.read_csv()로 csv 파일 읽어들이기\n",
    "train_org = pd.read_csv('../data/train.csv')\n",
    "test_org = pd.read_csv('../data/test.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# Identify object-type columns excluding 'Status'\n",
    "object_columns = train_org.select_dtypes(include=['object']).columns.drop('Status')\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert object-type columns to numerical using Label Encoding\n",
    "for col in object_columns:\n",
    "    train_org[col] = label_encoder.fit_transform(train_org[col])\n",
    "    test_org[col] = label_encoder.transform(test_org[col])\n",
    "\n",
    "# 수치형 입력 데이터, 범주형 입력 데이터, 출력 데이터로 구분하기\n",
    "train_X_num = train_org[['N_Days', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']]\n",
    "train_X_cat = train_org[object_columns]\n",
    "train_y = train_org['Status']\n",
    "\n",
    "# test 데이터도 동일하게 처리\n",
    "test_X_num = test_org[['N_Days', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']]\n",
    "test_X_cat = test_org[object_columns]\n",
    "\n",
    "# 수치형 입력 데이터 전처리\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X_num)\n",
    "test_X_scaled = scaler.transform(test_X_num)\n",
    "\n",
    "# Numpy Data인 X_scaled 데이터를 DataFrame으로 변환\n",
    "train_X_scaled = pd.DataFrame(data=train_X_scaled, index=train_X_num.index, columns=train_X_num.columns)\n",
    "test_X_scaled = pd.DataFrame(data=test_X_scaled, index=test_X_num.index, columns=test_X_num.columns)\n",
    "\n",
    "# 입력 데이터 통합\n",
    "train_X = pd.concat([train_X_scaled, train_X_cat], axis=1)\n",
    "test_X = pd.concat([test_X_scaled, test_X_cat], axis=1)\n",
    "\n",
    "# train_test_split() 함수로 학습 데이터와 검증 데이터 분리하기\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.3, random_state=1)\n",
    "\n",
    "# 'Status' 열 매핑\n",
    "status_mapping = {'C': 0, 'CL': 1, 'D': 2}\n",
    "train_org['Status'] = train_org['Status'].map(status_mapping)\n",
    "y_train = train_org['Status'].loc[X_train.index]  # X_train에 해당하는 'Status' 값을 y_train에 할당\n",
    "y_val = train_org['Status'].loc[X_val.index]      # X_val에 해당하는 'Status' 값을 y_val에 할당\n",
    "\n",
    "# XGBClassifier 모델 생성/학습\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict를 수행하고 classification_report() 결과 출력하기\n",
    "pred = model_xgb.predict(X_val)\n",
    "print(classification_report(y_val, pred))\n",
    "\n",
    "# 'Status'에 대한 원-핫 인코딩 적용\n",
    "encoder = OneHotEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1)).toarray()\n",
    "y_val_encoded = encoder.transform(y_val.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "# One-vs-Rest 방식을 사용한 다중 클래스 분류기 생성 및 학습\n",
    "ovr_model_xgb = OneVsRestClassifier(XGBClassifier())\n",
    "ovr_model_xgb.fit(X_train, y_train_encoded)\n",
    "\n",
    "# 테스트 데이터에 대한 확률 예측\n",
    "test_predictions_probs = model_xgb.predict_proba(test_X)\n",
    "\n",
    "# 예측된 확률을 submission 파일에 추가\n",
    "# 열 이름을 'id', 'Status_C', 'Status_CL', 'Status_D'로 설정\n",
    "column_names = ['Status_C', 'Status_CL', 'Status_D']\n",
    "submission = pd.DataFrame(test_predictions_probs, columns=column_names)\n",
    "submission = pd.concat([sample_submission['id'], submission], axis=1)\n",
    "\n",
    "# 결과를 submission_ver2.csv 파일로 저장\n",
    "submission.to_csv('../data/submission_ver3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML 객체 초기화\n",
    "automl = AutoML(mode=\"Compete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_2\n",
      "The task is multiclass_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Decision Tree', 'Linear', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree logloss 0.480908 trained in 0.25 seconds\n",
      "Adjust validation. Remove: 1_DecisionTree\n",
      "Validation strategy: 10-fold CV Shuffle,Stratify\n",
      "* Step simple_algorithms will try to check up to 4 models\n",
      "1_DecisionTree logloss 0.532945 trained in 1.53 seconds\n",
      "2_DecisionTree logloss 0.538758 trained in 1.41 seconds\n",
      "3_DecisionTree logloss 0.538758 trained in 1.41 seconds\n",
      "4_Linear logloss 0.53319 trained in 9.87 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "5_Default_LightGBM logloss 0.461241 trained in 9.84 seconds\n",
      "6_Default_Xgboost logloss 0.459219 trained in 7.89 seconds\n",
      "7_Default_CatBoost logloss 0.457631 trained in 9.56 seconds\n",
      "8_Default_NeuralNetwork logloss 0.535415 trained in 11.37 seconds\n",
      "9_Default_RandomForest logloss 0.506294 trained in 13.79 seconds\n",
      "10_Default_ExtraTrees logloss 0.53733 trained in 10.04 seconds\n",
      "11_Default_NearestNeighbors logloss 1.331127 trained in 2.98 seconds\n",
      "* Step not_so_random will try to check up to 61 models\n",
      "21_LightGBM logloss 0.450967 trained in 6.73 seconds\n",
      "12_Xgboost logloss 0.464065 trained in 9.13 seconds\n",
      "30_CatBoost logloss 0.457547 trained in 9.23 seconds\n",
      "39_RandomForest logloss 0.503219 trained in 11.61 seconds\n",
      "48_ExtraTrees logloss 0.55609 trained in 8.96 seconds\n",
      "57_NeuralNetwork logloss 0.541483 trained in 12.26 seconds\n",
      "66_NearestNeighbors logloss 1.151852 trained in 3.14 seconds\n",
      "22_LightGBM logloss 0.457489 trained in 6.37 seconds\n",
      "13_Xgboost logloss 0.471247 trained in 9.38 seconds\n",
      "31_CatBoost logloss 0.460249 trained in 9.62 seconds\n",
      "40_RandomForest logloss 0.482394 trained in 15.22 seconds\n",
      "49_ExtraTrees logloss 0.508562 trained in 11.26 seconds\n",
      "58_NeuralNetwork logloss 0.528821 trained in 12.57 seconds\n",
      "67_NearestNeighbors logloss 1.149679 trained in 3.57 seconds\n",
      "23_LightGBM logloss 0.462077 trained in 10.27 seconds\n",
      "14_Xgboost logloss 0.446651 trained in 8.33 seconds\n",
      "32_CatBoost logloss 0.459245 trained in 9.97 seconds\n",
      "41_RandomForest logloss 0.518895 trained in 12.94 seconds\n",
      "50_ExtraTrees logloss 0.557181 trained in 7.83 seconds\n",
      "59_NeuralNetwork logloss 0.536725 trained in 13.2 seconds\n",
      "68_NearestNeighbors logloss 1.149679 trained in 3.95 seconds\n",
      "24_LightGBM logloss 0.473534 trained in 12.55 seconds\n",
      "15_Xgboost logloss 0.453478 trained in 7.37 seconds\n",
      "33_CatBoost logloss 0.461453 trained in 11.68 seconds\n",
      "42_RandomForest logloss 0.486462 trained in 12.96 seconds\n",
      "51_ExtraTrees logloss 0.525199 trained in 14.94 seconds\n",
      "60_NeuralNetwork logloss 0.561438 trained in 13.79 seconds\n",
      "69_NearestNeighbors logloss 1.151852 trained in 4.2 seconds\n",
      "25_LightGBM logloss 0.451488 trained in 7.25 seconds\n",
      "16_Xgboost logloss 0.451553 trained in 9.5 seconds\n",
      "34_CatBoost logloss 0.455583 trained in 9.78 seconds\n",
      "43_RandomForest logloss 0.518057 trained in 13.71 seconds\n",
      "52_ExtraTrees logloss 0.568478 trained in 11.76 seconds\n",
      "61_NeuralNetwork logloss 0.539436 trained in 14.9 seconds\n",
      "70_NearestNeighbors logloss 1.767928 trained in 4.46 seconds\n",
      "26_LightGBM logloss 0.451788 trained in 14.86 seconds\n",
      "17_Xgboost logloss 0.447722 trained in 9.84 seconds\n",
      "35_CatBoost logloss 0.458361 trained in 10.02 seconds\n",
      "44_RandomForest logloss 0.486692 trained in 18.7 seconds\n",
      "53_ExtraTrees logloss 0.505747 trained in 15.16 seconds\n",
      "62_NeuralNetwork logloss 0.521398 trained in 14.59 seconds\n",
      "71_NearestNeighbors logloss 1.151852 trained in 4.79 seconds\n",
      "27_LightGBM logloss 0.459227 trained in 11.96 seconds\n",
      "18_Xgboost logloss 0.447275 trained in 12.4 seconds\n",
      "36_CatBoost logloss 0.457327 trained in 14.01 seconds\n",
      "45_RandomForest logloss 0.49597 trained in 15.44 seconds\n",
      "54_ExtraTrees logloss 0.526185 trained in 17.45 seconds\n",
      "63_NeuralNetwork logloss 0.525612 trained in 13.79 seconds\n",
      "72_NearestNeighbors logloss 1.768318 trained in 5.33 seconds\n",
      "28_LightGBM logloss 0.456705 trained in 8.21 seconds\n",
      "19_Xgboost logloss 0.452536 trained in 10.44 seconds\n",
      "37_CatBoost logloss 0.459038 trained in 9.12 seconds\n",
      "46_RandomForest logloss 0.503553 trained in 14.49 seconds\n",
      "55_ExtraTrees logloss 0.554967 trained in 18.71 seconds\n",
      "64_NeuralNetwork logloss 0.562 trained in 15.59 seconds\n",
      "29_LightGBM logloss 0.453147 trained in 9.18 seconds\n",
      "20_Xgboost logloss 0.454399 trained in 14.3 seconds\n",
      "38_CatBoost logloss 0.460473 trained in 17.14 seconds\n",
      "47_RandomForest logloss 0.494268 trained in 16.33 seconds\n",
      "56_ExtraTrees logloss 0.540911 trained in 14.89 seconds\n",
      "65_NeuralNetwork logloss 0.541199 trained in 15.16 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: Edema_sum_Bilirubin\n",
      "Add Golden Feature: Ascites_sum_Bilirubin\n",
      "Add Golden Feature: Hepatomegaly_sum_Bilirubin\n",
      "Add Golden Feature: Spiders_sum_Bilirubin\n",
      "Add Golden Feature: Sex_sum_Bilirubin\n",
      "Add Golden Feature: Bilirubin_diff_Sex\n",
      "Add Golden Feature: Bilirubin_diff_Hepatomegaly\n",
      "Add Golden Feature: Bilirubin_diff_Spiders\n",
      "Add Golden Feature: Hepatomegaly_ratio_Bilirubin\n",
      "Add Golden Feature: Hepatomegaly_sum_Copper\n",
      "Created 10 Golden Features in 10.53 seconds.\n",
      "14_Xgboost_GoldenFeatures logloss 0.453055 trained in 21.2 seconds\n",
      "18_Xgboost_GoldenFeatures logloss 0.456344 trained in 16.04 seconds\n",
      "17_Xgboost_GoldenFeatures logloss 0.451345 trained in 11.4 seconds\n",
      "* Step kmeans_features will try to check up to 3 models\n",
      "14_Xgboost_KMeansFeatures logloss 0.457336 trained in 15.95 seconds\n",
      "18_Xgboost_KMeansFeatures logloss 0.462368 trained in 20.55 seconds\n",
      "17_Xgboost_KMeansFeatures logloss 0.455123 trained in 14.71 seconds\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "14_Xgboost_RandomFeature logloss 0.450003 trained in 14.59 seconds\n",
      "Drop features ['random_feature', 'Sex', 'Drug', 'Ascites']\n",
      "* Step features_selection will try to check up to 6 models\n",
      "14_Xgboost_SelectedFeatures logloss 0.448361 trained in 11.69 seconds\n",
      "21_LightGBM_SelectedFeatures logloss 0.451452 trained in 9.2 seconds\n",
      "34_CatBoost_SelectedFeatures logloss 0.457602 trained in 11.87 seconds\n",
      "40_RandomForest_SelectedFeatures logloss 0.482576 trained in 17.3 seconds\n",
      "53_ExtraTrees_SelectedFeatures logloss 0.504092 trained in 15.98 seconds\n",
      "62_NeuralNetwork_SelectedFeatures logloss 0.522612 trained in 15.65 seconds\n",
      "* Step hill_climbing_1 will try to check up to 34 models\n",
      "73_Xgboost logloss 0.446574 trained in 11.08 seconds\n",
      "74_Xgboost logloss 0.448453 trained in 11.08 seconds\n",
      "75_Xgboost logloss 0.448622 trained in 15.5 seconds\n",
      "76_Xgboost logloss 0.450228 trained in 15.43 seconds\n",
      "77_Xgboost logloss 0.447025 trained in 11.25 seconds\n",
      "78_Xgboost logloss 0.44819 trained in 11.01 seconds\n",
      "79_LightGBM logloss 0.450876 trained in 10.3 seconds\n",
      "80_LightGBM_SelectedFeatures logloss 0.450271 trained in 9.81 seconds\n",
      "81_LightGBM logloss 0.457651 trained in 9.84 seconds\n",
      "82_LightGBM logloss 0.451828 trained in 9.68 seconds\n",
      "83_CatBoost logloss 0.456098 trained in 11.65 seconds\n",
      "84_CatBoost logloss 0.462884 trained in 13.0 seconds\n",
      "85_CatBoost logloss 0.455972 trained in 19.34 seconds\n",
      "86_CatBoost logloss 0.456173 trained in 22.2 seconds\n",
      "87_CatBoost logloss 0.457141 trained in 13.06 seconds\n",
      "88_RandomForest logloss 0.48267 trained in 21.78 seconds\n",
      "89_RandomForest logloss 0.482667 trained in 16.68 seconds\n",
      "90_RandomForest_SelectedFeatures logloss 0.481742 trained in 23.79 seconds\n",
      "91_RandomForest_SelectedFeatures logloss 0.484488 trained in 20.08 seconds\n",
      "92_RandomForest logloss 0.486515 trained in 22.5 seconds\n",
      "93_RandomForest logloss 0.487214 trained in 16.66 seconds\n",
      "94_ExtraTrees_SelectedFeatures logloss 0.505672 trained in 14.79 seconds\n",
      "95_ExtraTrees logloss 0.506695 trained in 14.48 seconds\n",
      "96_ExtraTrees logloss 0.514774 trained in 15.89 seconds\n",
      "97_ExtraTrees logloss 0.507411 trained in 15.82 seconds\n",
      "98_NeuralNetwork logloss 0.518382 trained in 16.78 seconds\n",
      "99_NeuralNetwork_SelectedFeatures logloss 0.518632 trained in 17.28 seconds\n",
      "100_NeuralNetwork logloss 0.537409 trained in 17.97 seconds\n",
      "101_NeuralNetwork logloss 0.532826 trained in 18.61 seconds\n",
      "102_DecisionTree logloss 0.540788 trained in 7.61 seconds\n",
      "103_DecisionTree logloss 0.563529 trained in 7.41 seconds\n",
      "104_DecisionTree logloss 0.558732 trained in 7.4 seconds\n",
      "105_NearestNeighbors logloss 1.330283 trained in 8.91 seconds\n",
      "106_NearestNeighbors logloss 1.330283 trained in 8.75 seconds\n",
      "* Step hill_climbing_2 will try to check up to 14 models\n",
      "107_Xgboost logloss 0.447944 trained in 13.66 seconds\n",
      "108_LightGBM_SelectedFeatures logloss 0.450831 trained in 13.9 seconds\n",
      "109_LightGBM logloss 0.449086 trained in 13.02 seconds\n",
      "110_CatBoost logloss 0.454402 trained in 17.42 seconds\n",
      "111_CatBoost logloss 0.457829 trained in 15.45 seconds\n",
      "112_CatBoost logloss 0.455391 trained in 16.54 seconds\n",
      "113_RandomForest_SelectedFeatures logloss 0.47849 trained in 24.24 seconds\n",
      "114_RandomForest logloss 0.479304 trained in 27.43 seconds\n",
      "115_RandomForest_SelectedFeatures logloss 0.479759 trained in 20.87 seconds\n",
      "116_ExtraTrees_SelectedFeatures logloss 0.503609 trained in 21.94 seconds\n",
      "117_ExtraTrees_SelectedFeatures logloss 0.505217 trained in 16.01 seconds\n",
      "118_ExtraTrees logloss 0.50397 trained in 15.7 seconds\n",
      "119_NeuralNetwork_SelectedFeatures logloss 0.527662 trained in 18.25 seconds\n",
      "120_DecisionTree logloss 0.565019 trained in 7.72 seconds\n",
      "* Step boost_on_errors will try to check up to 1 model\n",
      "73_Xgboost_BoostOnErrors logloss 0.448928 trained in 12.9 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.439024 trained in 111.02 seconds\n",
      "* Step stack will try to check up to 60 models\n",
      "73_Xgboost_Stacked logloss 0.454138 trained in 36.19 seconds\n",
      "109_LightGBM_Stacked logloss 0.453146 trained in 17.6 seconds\n",
      "110_CatBoost_Stacked logloss 0.447594 trained in 41.04 seconds\n",
      "113_RandomForest_SelectedFeatures_Stacked logloss 0.45081 trained in 231.32 seconds\n",
      "116_ExtraTrees_SelectedFeatures_Stacked logloss 0.447005 trained in 65.57 seconds\n",
      "98_NeuralNetwork_Stacked logloss 0.491154 trained in 27.56 seconds\n",
      "14_Xgboost_Stacked logloss 0.452854 trained in 38.19 seconds\n",
      "80_LightGBM_SelectedFeatures_Stacked logloss 0.452185 trained in 18.03 seconds\n",
      "112_CatBoost_Stacked logloss 0.448696 trained in 28.95 seconds\n",
      "114_RandomForest_Stacked logloss 0.450977 trained in 237.91 seconds\n",
      "118_ExtraTrees_Stacked logloss 0.448496 trained in 59.61 seconds\n",
      "99_NeuralNetwork_SelectedFeatures_Stacked logloss 0.476933 trained in 28.0 seconds\n",
      "77_Xgboost_Stacked logloss 0.450034 trained in 29.22 seconds\n",
      "108_LightGBM_SelectedFeatures_Stacked logloss 0.452683 trained in 18.02 seconds\n",
      "34_CatBoost_Stacked logloss 0.45004 trained in 36.47 seconds\n",
      "115_RandomForest_SelectedFeatures_Stacked logloss 0.450442 trained in 204.17 seconds\n",
      "53_ExtraTrees_SelectedFeatures_Stacked logloss 0.449535 trained in 71.26 seconds\n",
      "62_NeuralNetwork_Stacked logloss 0.476787 trained in 24.97 seconds\n",
      "18_Xgboost_Stacked logloss 0.459781 trained in 70.83 seconds\n",
      "79_LightGBM_Stacked logloss 0.453417 trained in 19.55 seconds\n",
      "85_CatBoost_Stacked logloss 0.449942 trained in 33.34 seconds\n",
      "90_RandomForest_SelectedFeatures_Stacked logloss 0.452484 trained in 153.62 seconds\n",
      "117_ExtraTrees_SelectedFeatures_Stacked logloss 0.449271 trained in 52.49 seconds\n",
      "62_NeuralNetwork_SelectedFeatures_Stacked logloss 0.493217 trained in 29.14 seconds\n",
      "17_Xgboost_Stacked logloss 0.451015 trained in 30.22 seconds\n",
      "* Step ensemble_stacked will try to check up to 1 model\n",
      "Ensemble_Stacked logloss 0.438904 trained in 160.2 seconds\n",
      "AutoML fit time: 3820.91 seconds\n",
      "AutoML best model: Ensemble_Stacked\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoML(mode=&#x27;Compete&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML(mode=&#x27;Compete&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AutoML(mode='Compete')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 예측 수행\n",
    "predictions = automl.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 제출 파일에 저장\n",
    "submission['Status'] = predictions\n",
    "submission.to_csv('../data/automl_submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KDY",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
